{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP\n",
    "\n",
    "- Do not change the content of the cells under __SETUP__ and __TESTS__*\n",
    "- Work only in the __YOUR WORK__ area*\n",
    "- Rename the notebook with your group at the end (subsitute XX with your group number).\n",
    "- Assign the results of each numbered question to the appropriate test variable. For example, the answer of `1.` should be assigned to `test_1`\n",
    "- Rounding: use the supplied function `hround` to round decimal numbers when instructed. It's important to use this function because there are [multiple ways to round numbers in Python](https://www.knowledgehut.com/blog/programming/python-rounding-numbers) and they may not result in the same value that the tester is testing against.\n",
    "- Ensure your run the cells under __SETUP__ before you run your work\n",
    "- Before you submit your work, ensure you clean up your notebook. Your notebook has to run without an error in order to be tested. The easiest way to ensure is to `Kernel->Restart & Run All`\n",
    "- Answers are provided below for your convenience\n",
    "- You will need to write a program to calculate the answers. Setting the answers to be their correct values without solving them is considered *hardcoding* and will result in zero grade for the assignment as well as a potential academic honesty violation.\n",
    "- You can also test your submission using [the online code tester](https://notebook-tester.safadi-puzzler.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT OR CHANGE THE CONTENT OF THIS CELL\n",
    "scenario = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "stop_words = set(_stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analytics\n",
    "\n",
    "In this question we will further analyze the tweet data set. \n",
    "We will extract word co-locations from the tweet text.\n",
    "Word colocations are sequences of words in text. For example \"big data\" is one word collocation because the words \"big\" and \"data\" come frequently together.\n",
    "\n",
    "1. First we will simplify the tweets. In this analysis, we do not care about the hashtags, mentions, or links. However, we want to keep them because they are part of the tweet. Therefore, we want to replace each hashtag with `HASHTAG` verbatim, each mention with `MENTION`, and each link with `LINK`. Take a look at `test_1` for how the first tweet look like. You need to simplify all tweets for the next step.\n",
    "2. Next, create a function `bigrams` that takes a string as a parameter and returns the bigrams in the string. A bigram is a pair of consecutive words. In the function use TextBlob to obtain the list of words in the text. Then write a loop that goes over the words and then combine each sequence of two consecutive words in a tuple. The tuples are added to the list that the function returns. Take a look at `test_2` for what the function returns on a sample text. Report the outcome of invoking this function on `\"A bigram is a pair of consecutive written words\"`\n",
    "3. Apply the function on the simplified text of each tweet. What are the bigrams of the first tweet.\n",
    "4. Count the frequencies of the bigrams. Report the ten most frequent bigrams in a list.\n",
    "5. As you see, the top frequent bigrams all contain hashtags, mentions, links and common English words. We want to filter out any bigram that contains `HASHTAG`, `MENTION`, `LINK`, or a common English word that is in the variable `stop_words`. Filter out the frequent bigrams and report the ten most frequent ones again.\n",
    "6. We are starting to see some topics emerging from this analysis. We want to extend the previous analysis to report trigrams which are sequences of three words. Write a function `trigrams` that is similar to the previous function but returns a list of trigrams in the passed string. Report the outcome of invoking the function on `\"A trigram is a three consecutive written words\"`\n",
    "7. What are the trigrams of the first tweet?\n",
    "8. What are the ten most frequent trigrams?\n",
    "9. What are the ten most frequent trigrams after filtering out `HASHTAG`, `MENTION`, `LINK`, and common English words?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweeter</th>\n",
       "      <th>level</th>\n",
       "      <th>hits</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do we need another CxO? RT @KirkDBorne: Hail t...</td>\n",
       "      <td>2014-02-11 19:05:23</td>\n",
       "      <td>433315847696687104</td>\n",
       "      <td>johnweathington</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1</td>\n",
       "      <td>2.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To the #analysts planning their future also on...</td>\n",
       "      <td>2012-05-25 11:08:55</td>\n",
       "      <td>205978750607822849</td>\n",
       "      <td>79dirk</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1</td>\n",
       "      <td>2.222976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#datascientist #bigdata what proportion of Big...</td>\n",
       "      <td>2014-01-10 16:27:51</td>\n",
       "      <td>421679791385751553</td>\n",
       "      <td>brwood</td>\n",
       "      <td>Individual</td>\n",
       "      <td>1</td>\n",
       "      <td>2.213131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could teams with complementary skills tackle t...</td>\n",
       "      <td>2014-07-16 11:38:53</td>\n",
       "      <td>489373601754124288</td>\n",
       "      <td>accenture_irl</td>\n",
       "      <td>Organization</td>\n",
       "      <td>2</td>\n",
       "      <td>2.434355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last week @hmason spoke about #innovation thro...</td>\n",
       "      <td>2014-10-18 10:12:01</td>\n",
       "      <td>523416199674494976</td>\n",
       "      <td>cdelancray</td>\n",
       "      <td>Individual</td>\n",
       "      <td>2</td>\n",
       "      <td>3.066636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            timestamp  \\\n",
       "0  Do we need another CxO? RT @KirkDBorne: Hail t...  2014-02-11 19:05:23   \n",
       "1  To the #analysts planning their future also on...  2012-05-25 11:08:55   \n",
       "2  #datascientist #bigdata what proportion of Big...  2014-01-10 16:27:51   \n",
       "3  Could teams with complementary skills tackle t...  2014-07-16 11:38:53   \n",
       "4  Last week @hmason spoke about #innovation thro...  2014-10-18 10:12:01   \n",
       "\n",
       "              tweetid          tweeter         level  hits     score  \n",
       "0  433315847696687104  johnweathington    Individual     1  2.086700  \n",
       "1  205978750607822849           79dirk    Individual     1  2.222976  \n",
       "2  421679791385751553           brwood    Individual     1  2.213131  \n",
       "3  489373601754124288    accenture_irl  Organization     2  2.434355  \n",
       "4  523416199674494976       cdelancray    Individual     2  3.066636  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Write code the calculate the following numbers. Store each answer in a variable `test_#`. For example, the answer for the first question should be stored in `test_1`\n",
    "- Before you submit your work, ensure you clean up your notebook. Your notebook has to run without an error in order to be tested. The easiest way to ensure is to `Kernel->Restart & Run All`\n",
    "- Answers are provided below for your convenience\n",
    "- __AGAIN__ Don't change anything in the __SETUP__ and __TEST__ sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=test_2=test_3=test_4=test_5=test_6=test_7=test_8=test_9=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['filter'] = data['text'].str.replace('@\\w+', 'MENTION').str.replace('#\\w+', 'HASHTAG').str.replace('http:[./\\w]+', 'LINK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = data['filter'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(text):\n",
    "    blob = TextBlob(text)\n",
    "    words = blob.words\n",
    "    res = []\n",
    "    for i in range(len(blob.words)-1):\n",
    "        res.append((words[i], words[i+1]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = bigrams(\"A bigram is a pair of consecutive written words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bigrams']=data['filter'].apply(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = data['bigrams'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(data['bigrams'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(freq.items(), columns = ['bigram', 'frequency'])\n",
    "df = df.sort_values('frequency', ascending=False)\n",
    "test_4 = list(df.head(10)['bigram'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or\n",
    "#sorted_freq = sorted(freq.items(), key=lambda x: -x[-1])\n",
    "#test_4 = sorted_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'Scientist'),\n",
       " ('data', 'scientist'),\n",
       " ('’', 's'),\n",
       " ('Big', 'Data'),\n",
       " ('Data', 'Scientists'),\n",
       " ('convoluted', 'world'),\n",
       " ('The', 'convoluted'),\n",
       " ('data', 'scientists'),\n",
       " ('data', 'science'),\n",
       " ('Data', 'Science')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['bigram'].apply(lambda x: x[0] not in stop_words and x[1] not in stop_words and x[0] not in [\"HASHTAG\", \"MENTION\", \"LINK\"] and x[1] not in [\"HASHTAG\", \"MENTION\", \"LINK\"])\n",
    "test_5 = list(df[mask].head(10)['bigram'].values)\n",
    "test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(text):\n",
    "    blob = TextBlob(text)\n",
    "    words = blob.words\n",
    "    res = []\n",
    "    for i in range(len(blob.words)-2):\n",
    "        res.append((words[i], words[i+1], words[i+2]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_6 = trigrams(\"A trigram is a three consecutive written words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['trigrams']=data['filter'].apply(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_7 = data['trigrams'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq3 = Counter(data['trigrams'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(freq3.items(), columns = ['trigram', 'frequency'])\n",
    "df3 = df3.sort_values('frequency', ascending=False)\n",
    "test_8 = list(df3.head(10)['trigram'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HASHTAG', 'HASHTAG', 'HASHTAG'),\n",
       " ('LINK', 'HASHTAG', 'HASHTAG'),\n",
       " ('HASHTAG', 'HASHTAG', 'LINK'),\n",
       " ('HASHTAG', 'LINK', 'HASHTAG'),\n",
       " ('a', 'HASHTAG', 'LINK'),\n",
       " ('LINK', 'via', 'MENTION'),\n",
       " ('MENTION', 'HASHTAG', 'HASHTAG'),\n",
       " ('via', 'MENTION', 'HASHTAG'),\n",
       " ('be', 'a', 'HASHTAG'),\n",
       " ('MENTION', 'LINK', 'HASHTAG')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'convoluted', 'world'),\n",
       " ('data', 'scientist', 'A'),\n",
       " ('2015', \"'s\", 'hottest'),\n",
       " (\"'s\", 'hottest', 'profession'),\n",
       " ('data', 'science', 'teams'),\n",
       " ('scientist', 'A', 'guide'),\n",
       " ('Scientist', '’', 'In'),\n",
       " ('Social', 'Media', 'Scientist'),\n",
       " ('’', 's', '2014'),\n",
       " ('s', '2014', 'Top')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df3['trigram'].apply(lambda x: x[0] not in stop_words and x[1] not in stop_words and x[2] not in stop_words and x[0] not in [\"HASHTAG\", \"MENTION\", \"LINK\"] and x[1] not in [\"HASHTAG\", \"MENTION\", \"LINK\"] and x[2] not in [\"HASHTAG\", \"MENTION\", \"LINK\"])\n",
    "test_9 = list(df3[mask].head(10)['trigram'].values)\n",
    "test_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do we need another CxO? RT MENTION: Hail to the Chief Data Officer HASHTAG LINK via MENTION HASHTAG HASHTAG'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST 1\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'bigram'),\n",
       " ('bigram', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'pair'),\n",
       " ('pair', 'of'),\n",
       " ('of', 'consecutive'),\n",
       " ('consecutive', 'written'),\n",
       " ('written', 'words')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 2\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Do', 'we'),\n",
       " ('we', 'need'),\n",
       " ('need', 'another'),\n",
       " ('another', 'CxO'),\n",
       " ('CxO', 'RT'),\n",
       " ('RT', 'MENTION'),\n",
       " ('MENTION', 'Hail'),\n",
       " ('Hail', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'Chief'),\n",
       " ('Chief', 'Data'),\n",
       " ('Data', 'Officer'),\n",
       " ('Officer', 'HASHTAG'),\n",
       " ('HASHTAG', 'LINK'),\n",
       " ('LINK', 'via'),\n",
       " ('via', 'MENTION'),\n",
       " ('MENTION', 'HASHTAG'),\n",
       " ('HASHTAG', 'HASHTAG')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 3\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HASHTAG', 'HASHTAG'),\n",
       " ('LINK', 'HASHTAG'),\n",
       " ('HASHTAG', 'LINK'),\n",
       " ('a', 'HASHTAG'),\n",
       " ('MENTION', 'HASHTAG'),\n",
       " ('via', 'MENTION'),\n",
       " ('MENTION', 'LINK'),\n",
       " ('the', 'HASHTAG'),\n",
       " ('MENTION', 'MENTION'),\n",
       " ('HASHTAG', 'MENTION')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 4\n",
    "test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'Scientist'),\n",
       " ('data', 'scientist'),\n",
       " ('’', 's'),\n",
       " ('Big', 'Data'),\n",
       " ('Data', 'Scientists'),\n",
       " ('convoluted', 'world'),\n",
       " ('The', 'convoluted'),\n",
       " ('data', 'scientists'),\n",
       " ('data', 'science'),\n",
       " ('Data', 'Science')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 5\n",
    "test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'trigram', 'is'),\n",
       " ('trigram', 'is', 'a'),\n",
       " ('is', 'a', 'three'),\n",
       " ('a', 'three', 'consecutive'),\n",
       " ('three', 'consecutive', 'written'),\n",
       " ('consecutive', 'written', 'words')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 6\n",
    "test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Do', 'we', 'need'),\n",
       " ('we', 'need', 'another'),\n",
       " ('need', 'another', 'CxO'),\n",
       " ('another', 'CxO', 'RT'),\n",
       " ('CxO', 'RT', 'MENTION'),\n",
       " ('RT', 'MENTION', 'Hail'),\n",
       " ('MENTION', 'Hail', 'to'),\n",
       " ('Hail', 'to', 'the'),\n",
       " ('to', 'the', 'Chief'),\n",
       " ('the', 'Chief', 'Data'),\n",
       " ('Chief', 'Data', 'Officer'),\n",
       " ('Data', 'Officer', 'HASHTAG'),\n",
       " ('Officer', 'HASHTAG', 'LINK'),\n",
       " ('HASHTAG', 'LINK', 'via'),\n",
       " ('LINK', 'via', 'MENTION'),\n",
       " ('via', 'MENTION', 'HASHTAG'),\n",
       " ('MENTION', 'HASHTAG', 'HASHTAG')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 7\n",
    "test_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HASHTAG', 'HASHTAG', 'HASHTAG'),\n",
       " ('LINK', 'HASHTAG', 'HASHTAG'),\n",
       " ('HASHTAG', 'HASHTAG', 'LINK'),\n",
       " ('HASHTAG', 'LINK', 'HASHTAG'),\n",
       " ('a', 'HASHTAG', 'LINK'),\n",
       " ('LINK', 'via', 'MENTION'),\n",
       " ('MENTION', 'HASHTAG', 'HASHTAG'),\n",
       " ('via', 'MENTION', 'HASHTAG'),\n",
       " ('be', 'a', 'HASHTAG'),\n",
       " ('MENTION', 'LINK', 'HASHTAG')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 8\n",
    "test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'convoluted', 'world'),\n",
       " ('data', 'scientist', 'A'),\n",
       " ('2015', \"'s\", 'hottest'),\n",
       " (\"'s\", 'hottest', 'profession'),\n",
       " ('data', 'science', 'teams'),\n",
       " ('scientist', 'A', 'guide'),\n",
       " ('Scientist', '’', 'In'),\n",
       " ('Social', 'Media', 'Scientist'),\n",
       " ('’', 's', '2014'),\n",
       " ('s', '2014', 'Top')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 9\n",
    "test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
